{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "PATH = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models/rendernet.py\n",
    "%run data_loaders/scannet_render_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model using its best weights unless otherwise specified\n",
    "def load_trained_model(train_id, checkpoint_name='model_best'):\n",
    "    model_path = os.path.join(PATH, 'saved/models/DNR', train_id)\n",
    "\n",
    "    # Load config file\n",
    "    config_file = os.path.join(model_path, \"config.json\")\n",
    "    if config_file:\n",
    "        with open(config_file, 'r') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "    # Load model weights\n",
    "    checkpoint_path = os.path.join(model_path, checkpoint_name) + '.pth'\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    # Load model with parameters from config file\n",
    "    model = RenderNet(config['arch']['args']['texture_size'],\n",
    "                     config['arch']['args']['texture_depth'])\n",
    "    \n",
    "    # Assign model weights and set to eval (not train) mode\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all models by train id\n",
    "def load_trained_models(train_ids):\n",
    "    models = {}\n",
    "    for train_id in train_ids:\n",
    "        models[train_id] = load_trained_model(train_id)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cereate a libtorch script file containing the model that can be loaded into C++\n",
    "def create_libtorch_script(model, train_id, checkpoint_name='model_best'):\n",
    "    sm = torch.jit.script(model)\n",
    "    model_script_name = 'DNR-{}-{}_model.pt'.format(train_id, checkpoint_name)\n",
    "    model_script_path = os.path.join(PATH, 'libtorch-models', model_script_name)\n",
    "    sm.save(model_script_path)\n",
    "    print(model_script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a model prediction\n",
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input)#, training=True)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    \n",
    "    _, h, w, c = test_input.shape\n",
    "    test_input_color = torch.zeros((h, w, 3))#, dtype=type(test_input))\n",
    "    test_input_color = test_input[:,:,:, 0]\n",
    "    tar = tar.permute(0, 2, 3, 1)\n",
    "    prediction = prediction.detach().permute(0, 2, 3, 1)\n",
    "\n",
    "    display_list = [test_input_color[0].numpy(), tar[0].numpy(), prediction[0].numpy()]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparison(display_images, title, title_color):\n",
    "    for i, image in enumerate(display_images):\n",
    "        display_images[i] = image.permute(0, 2, 3, 1)\n",
    "        \n",
    "    # Should assert that rows * cols == len(title) == len(display_images)\n",
    "    img_per_row = 2 # 3\n",
    "    rows, cols = np.ceil(len(display_images) / img_per_row), np.min([len(display_images), img_per_row])\n",
    "    plt.figure(figsize=(35 * cols,30 * rows))\n",
    "    for i in range(len(display_images)):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.title(title[i], color=title_color[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_images[i][0].numpy() * 0.5 + 0.5)\n",
    "        #plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Execute code below --##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List train ids here #\n",
    "#train_ids = ['0618_155900', '0619_015820', '0618_074752']\n",
    "#load_trained_models(train_ids)\n",
    "train_ids = ['0625_181653', '0625_114333', '0626_000812']\n",
    "#models = [None]*3\n",
    "models = {}\n",
    "models[train_ids[0]]  = load_trained_model('0625_181653', 'checkpoint-epoch120')\n",
    "models[train_ids[1]]  = load_trained_model('0625_114333')\n",
    "models[train_ids[2]]  = load_trained_model('0626_000812')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a single validation input, ground truth and preducted sample from the first model #\n",
    "print(len(train_ids))\n",
    "loader = UVDataLoader('data', 1, True, 6).split_validation(size=(256, 342))\n",
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    for train_id in train_ids:\n",
    "        print('Train ID:', train_id)\n",
    "        model = models[train_id]  \n",
    "        generate_images(model, data, target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show a validation sample prediction for each model #\n",
    "\n",
    "display_images = []\n",
    "# Load from the validatiom dataset\n",
    "loader = UVDataLoader('data', 1, True, 6).split_validation()\n",
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    # Add target image used to generate predictions\n",
    "    display_images.append(target)\n",
    "\n",
    "    # Add predictions\n",
    "    for train_id in train_ids:\n",
    "        # Get the trained model\n",
    "        model = models[train_id]\n",
    "        \n",
    "        # Make a prediction using the model\n",
    "        prediction = model(data)\n",
    "        prediction = prediction.detach()\n",
    "        display_images.append(prediction)\n",
    "    break\n",
    "\n",
    "# Plot results\n",
    "title = ['Ground Truth', 'Prediction Exp 1: 521 train, 104 val',\n",
    "         'Prediction Exp 1: 1042 train, 208 val',\n",
    "         'Prediction Exp 1: 2083 train, 417 val']\n",
    "title_color = ['black', 'magenta', 'green', 'blue']\n",
    "\n",
    "generate_comparison(display_images, title, title_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a libtorch script file from model #\n",
    "train_id = '0626_000812'\n",
    "print(train_id)\n",
    "create_libtorch_script(models[train_id], train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
