{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralTexture(nn.Module):\n",
    "    def __init__(self, size, depth):\n",
    "        super(NeuralTexture, self).__init__()\n",
    "        # Init between [-1,1] to match our output texture\n",
    "        # dim0 = 1 to be dimensionally compatible with grid_sample\n",
    "\n",
    "        #self.texture = torch.nn.Parameter(torch.FloatTensor(1, depth, size, size).uniform_(-1, 1),\n",
    "        #                                  requires_grad=True)\n",
    "        self.texture = torch.Tensor([1.0, 10.0]).unsqueeze(0).unsqueeze(0).unsqueeze(3)\n",
    "        #self.texture = torch.Tensor([[1.0, 10.0],[1.0, 10.0]]).unsqueeze(1).unsqueeze(3)\n",
    "        print('texture shape:', self.texture.shape)\n",
    "        print('texture:', self.texture)\n",
    "        #self.texture = torch.Tensor([1.0, 10.0]).unsqueeze(0).unsqueeze(0).unsqueeze(3)\n",
    "        self.texture = torch.nn.Parameter(self.texture, requires_grad=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # TODO: Make self.textures work with batch_size > 1\n",
    "        # TODO: NOTE: grid_sample samples texture as (row, col) while uv coordinates are\n",
    "        #  given as (u, v) s.t. (row, col) == (2*v - 1, 2*u - 1). We'll convert the range\n",
    "        #  from [0,1] to [-1,1] like above but we won't bother swapping u and v (for now).\n",
    "        #  This shouldn't be a problem as long as we're consistent but should eventually\n",
    "        #  be fixed for correctness.\n",
    "        #grid = input#2 * input - 1\n",
    "        #sample = F.grid_sample(self.texture, grid, align_corners=True)\n",
    "\n",
    "        #grid = 2 * input - 1\n",
    "        #for i in range(grid.shape[0]):\n",
    "        #    s = F.grid_sample(self.texture, grid[i, :, :, :].unsqueeze(0), align_corners=False)\n",
    "        #\n",
    "        #    if i == 0:\n",
    "        #        samples = s\n",
    "        #    else:\n",
    "        #        samples = torch.cat((samples, s), dim=0)\n",
    "        #\n",
    "        #return samples\n",
    "\n",
    "        # TODO: Does expanding the texture create any problems with training? Can we\n",
    "        #  expand just once in __init__()?\n",
    "        # TODO: Is training slowed by averaging over zeros that exist due to some pixels that\n",
    "        #  have yet tgo be trained?\n",
    "        #grid = 2 * input - 1\n",
    "        grid = input\n",
    "        sample = F.grid_sample(self.texture.expand(grid.shape[0], -1, -1, -1), grid, align_corners=True)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 1\n",
    "size = 3\n",
    "x = torch.zeros(2, 1, 1, 2)\n",
    "x[0, :, :, :] = 0\n",
    "x[1, :, :, :] = 0.5\n",
    "#x = torch.zeros(1, 2, 1, 2)\n",
    "#x[:, 0, :, :] = 0\n",
    "#x[:, 1, :, :] = 0.5\n",
    "#x = torch.zeros(2, 1, 1, 2) + 0.5\n",
    "x.requires_grad = False\n",
    "y = torch.Tensor([0.9, 0.9]).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "#y = torch.Tensor([0.9, 0.9]).unsqueeze(0).unsqueeze(0).unsqueeze(3)\n",
    "y.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = NeuralTexture(size, depth)\n",
    "loss_fn = torch.nn.L1Loss(reduction='none')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print('x shape:', x.shape)\n",
    "print('x:', x)\n",
    "print(model.texture)\n",
    "print('y shape:', y.shape)\n",
    "print('y:', y)\n",
    "\n",
    "y_pred = model(x)\n",
    "print('y_pred shape:', y_pred.shape)\n",
    "print('y_pred:', y_pred)\n",
    "\n",
    "loss = loss_fn(y_pred, y)\n",
    "print('loss shape:', loss.shape)\n",
    "print('loss:', loss)\n",
    "\n",
    "loss = loss.mean()\n",
    "print('mean loss:', loss)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "print('gradients:', model.texture.grad)\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
